import { Ollama } from 'ollama';
import { vectorStoreService } from './vectorStore.service';
import { PrismaClient } from '@prisma/client';

const prisma = new PrismaClient();

/**
 * RAG (Retrieval-Augmented Generation) Service
 * Combines vector search with LLM generation
 */
class RAGService {
    private ollama: Ollama;
    private model: string;

    constructor() {
        // Use IPv4 to avoid IPv6 connection issues
        this.ollama = new Ollama({ host: 'http://127.0.0.1:11434' });
        this.model = 'gemma3:4b'; // Using gemma3:4b model
    }

    /**
     * Initialize vector store with course data
     */
    async initializeVectorStore(): Promise<void> {
        console.log('üîÑ Initializing vector store with course data...');

        // Clear existing documents
        vectorStoreService.clear();

        // Fetch all courses with related data
        const courses = await prisma.course.findMany({
            include: {
                teacher: {
                    select: {
                        firstName: true,
                        lastName: true,
                        username: true,
                    },
                },
                category: true,
                modules: {
                    include: {
                        contents: true,
                    },
                },
            },
        });

        console.log(`üìö Found ${courses.length} courses to index`);

        // Create documents for each course
        for (const course of courses) {
            // 1. Course overview document
            const courseContent = `
Kh√≥a h·ªçc: ${course.title}
Gi·∫£ng vi√™n: ${course.teacher.firstName} ${course.teacher.lastName} (${course.teacher.username})
Danh m·ª•c: ${course.category.name}
M√¥ t·∫£: ${course.description}
Gi√°: ${course.price === 0 ? 'Mi·ªÖn ph√≠' : `${course.price} VND`}
            `.trim();

            await vectorStoreService.addDocument(courseContent, {
                courseId: course.id,
                courseTitle: course.title,
                type: 'course',
                teacherName: `${course.teacher.firstName} ${course.teacher.lastName}`,
                category: course.category.name,
                price: course.price,
            });

            // 2. Module documents
            for (const module of course.modules) {
                const moduleContent = `
Kh√≥a h·ªçc: ${course.title}
Ch∆∞∆°ng: ${module.title}
Th·ª© t·ª±: ${module.order}
                `.trim();

                await vectorStoreService.addDocument(moduleContent, {
                    courseId: course.id,
                    courseTitle: course.title,
                    type: 'module',
                    moduleTitle: module.title,
                    moduleOrder: module.order,
                });

                // 3. Content documents
                for (const content of module.contents) {
                    const contentText = `
Kh√≥a h·ªçc: ${course.title}
Ch∆∞∆°ng: ${module.title}
B√†i h·ªçc: ${content.title}
Lo·∫°i: ${content.contentType}
Th·ª© t·ª±: ${content.order}
                    `.trim();

                    await vectorStoreService.addDocument(contentText, {
                        courseId: course.id,
                        courseTitle: course.title,
                        type: 'content',
                        moduleTitle: module.title,
                        contentTitle: content.title,
                        contentType: content.contentType,
                    });
                }
            }
        }

        vectorStoreService.setInitialized(true);
        console.log(`‚úÖ Vector store initialized with ${vectorStoreService.getDocumentCount()} documents`);
    }

    /**
     * Generate answer using RAG pipeline
     */
    async generateAnswer(
        question: string,
        courseId?: number
    ): Promise<{
        answer: string;
        sources: Array<{
            courseTitle: string;
            content: string;
            score: number;
        }>;
    }> {
        // Check if vector store is initialized
        if (!vectorStoreService.getIsInitialized()) {
            await this.initializeVectorStore();
        }

        // 1. Retrieve relevant documents
        const searchResults = await vectorStoreService.search(
            question,
            5,
            courseId ? { courseId } : undefined
        );

        // 2. Prepare context from retrieved documents
        const context = searchResults
            .map((result, idx) => `[T√†i li·ªáu ${idx + 1}]\n${result.document.content}`)
            .join('\n\n');

        // 3. Create prompt for LLM
        const prompt = `B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh cho n·ªÅn t·∫£ng h·ªçc tr·ª±c tuy·∫øn E-Learning. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n th√¥ng tin v·ªÅ c√°c kh√≥a h·ªçc.

Th√¥ng tin kh√≥a h·ªçc:
${context}

C√¢u h·ªèi: ${question}

H√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c, h·ªØu √≠ch v√† th√¢n thi·ªán. N·∫øu th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, h√£y n√≥i r√µ v√† ƒë·ªÅ xu·∫•t ng∆∞·ªùi d√πng t√¨m hi·ªÉu th√™m. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.

Tr·∫£ l·ªùi:`;

        // 4. Generate answer using LLM
        const response = await this.ollama.generate({
            model: this.model,
            prompt: prompt,
            stream: false,
        });

        // 5. Prepare sources
        const sources = searchResults.map((result) => ({
            courseTitle: result.document.metadata.courseTitle,
            content: result.document.content,
            score: result.score,
        }));

        return {
            answer: response.response,
            sources,
        };
    }

    /**
     * Stream answer using RAG pipeline
     */
    async *streamAnswer(
        question: string,
        courseId?: number
    ): AsyncGenerator<string, void, unknown> {
        // Check if vector store is initialized
        if (!vectorStoreService.getIsInitialized()) {
            await this.initializeVectorStore();
        }

        // 1. Retrieve relevant documents
        const searchResults = await vectorStoreService.search(
            question,
            5,
            courseId ? { courseId } : undefined
        );

        // 2. Prepare context
        const context = searchResults
            .map((result, idx) => `[T√†i li·ªáu ${idx + 1}]\n${result.document.content}`)
            .join('\n\n');

        // 3. Create prompt
        const prompt = `B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh cho n·ªÅn t·∫£ng h·ªçc tr·ª±c tuy·∫øn E-Learning. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n th√¥ng tin v·ªÅ c√°c kh√≥a h·ªçc.

Th√¥ng tin kh√≥a h·ªçc:
${context}

C√¢u h·ªèi: ${question}

H√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c, h·ªØu √≠ch v√† th√¢n thi·ªán. N·∫øu th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, h√£y n√≥i r√µ v√† ƒë·ªÅ xu·∫•t ng∆∞·ªùi d√πng t√¨m hi·ªÉu th√™m. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.

Tr·∫£ l·ªùi:`;

        // 4. Stream response
        const stream = await this.ollama.generate({
            model: this.model,
            prompt: prompt,
            stream: true,
        });

        for await (const chunk of stream) {
            yield chunk.response;
        }
    }
}

export const ragService = new RAGService();

